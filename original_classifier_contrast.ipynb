{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM for sequence classification in the IMDB dataset\n",
    "from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE = int(\"FFFFFFF\",16)\n",
    "# max_num = int(int(\"FFFFFF\",16)/int(\"FFFFF\",16)+1)\n",
    "max_num = int(int(\"FFFFFF\",16)/int(\"FFFFF\",16)+1)\n",
    "# max_num = 2\n",
    "SEGMENT = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_payload(hex_string, token_length = 4):\n",
    "    # token_length = 4 \n",
    "    # new token length according to the max tokens for the embedding; which is original 6   \n",
    "    regex_pattern = '.{1,' + str(token_length) + '}'\n",
    "    return ' '.join(re.findall(regex_pattern, hex_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n",
    "top_n = 500 # take first 10 packets for test\n",
    "filename = os.path.basename(csv_file)\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df.dropna(subset = ['tcp.payload'], inplace=True)\n",
    "\n",
    "df['tokenizer_content'] = df['tcp.payload'].apply(tokenizer_payload)\n",
    "# encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "df[\"n_tokens\"] = df.tokenizer_content.apply(lambda x: len(encoding.encode(x)))\n",
    "df = df[df.n_tokens <= max_tokens].tail(top_n)\n",
    "# df = df[df.n_tokens <= max_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_normal_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "#     new_data = data.drop([0], axis = 0)\n",
    "    new_data = data\n",
    "    new_data = new_data.drop(new_data[pd.isna(new_data['tcp.payload'])].index)\n",
    "    new_data.drop(new_data.head(20).index, inplace = True)\n",
    "    new_data.to_csv('temp.csv',index = False)\n",
    "    payload = pd.read_csv('temp.csv')\n",
    "    \n",
    "    X_set = []\n",
    "    for i in range(len(payload['tcp.payload'])):\n",
    "        # print(i)\n",
    "        sample = payload['tcp.payload'][i]\n",
    "        # print(sample)\n",
    "        j = 0\n",
    "        sample_list = []\n",
    "        while j < len(sample):\n",
    "            sample_list.append(int(sample[j:j+SEGMENT],16)/float(SCALE))\n",
    "            j = j+SEGMENT\n",
    "        if j>len(sample):\n",
    "            sample_list.append(int(sample[j-SEGMENT:],16)/float(SCALE))\n",
    "        \n",
    "        X_set.append(np.array(sample_list))\n",
    "    y_set = [0]*len(X_set)\n",
    "    print(type(X_set))\n",
    "    print(X_set[0])\n",
    "    return np.array(X_set),np.array(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_attack_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "#     new_data = data.drop([0], axis = 0)\n",
    "    new_data = data\n",
    "    new_data = new_data.drop(new_data[pd.isna(new_data['tcp.payload'])].index)\n",
    "#     if filename == \"../pcap file/attack file/csv_file/attack_DDoS.csv\":     \n",
    "#         new_data.to_csv('sequence.csv',index = False)\n",
    "    new_data.drop(new_data.head(20).index, inplace = True)\n",
    "    new_data.to_csv('temp.csv',index = False)\n",
    "    payload = pd.read_csv('temp.csv')\n",
    "    \n",
    "    X_set = []\n",
    "    for i in range(len(payload['tcp.payload'])):\n",
    "        # print(i)\n",
    "        sample = payload['tcp.payload'][i]\n",
    "        # print(sample)\n",
    "        j = 0\n",
    "        sample_list = []\n",
    "        while j < len(sample):\n",
    "            sample_list.append(int(sample[j:j+SEGMENT],16)/float(SCALE))\n",
    "            j = j+SEGMENT\n",
    "        if j>len(sample):\n",
    "            sample_list.append(int(sample[j-SEGMENT:],16)/float(SCALE))\n",
    "        X_set.append(sample_list)\n",
    "\n",
    "    y_set = [1]*len(X_set)\n",
    "    print(type(X_set))\n",
    "    print(X_set[0])\n",
    "    return X_set,y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X,y,ratio):\n",
    "    if(len(X)!=len(y)):\n",
    "        return false\n",
    "    divide = math.ceil(len(X)*ratio)\n",
    "    X_train = X[:divide]\n",
    "    X_test = X[divide:]\n",
    "    y_train = y[:divide]\n",
    "    y_test = y[divide:]\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[6.18714347e+00 1.79802998e+00 1.15400727e+01 1.54010622e+01\n",
      " 7.12486495e+00 8.68088516e+00 1.44769003e+01 1.50589067e+01\n",
      " 5.71513505e+00 1.03861038e+01 1.41187771e+01 1.10396274e+01\n",
      " 4.18805705e-03 7.42852371e+00 7.40260671e-01 5.72084279e+00\n",
      " 3.74007766e+00 4.12769882e-01 8.95142521e+00 1.00958337e+01\n",
      " 1.37748540e+01 5.22551878e-01 5.08022117e+00 3.44219633e+00\n",
      " 5.23444979e+00 4.33722104e+00 6.33538437e+00 1.27822948e+01\n",
      " 1.10705133e+01 1.24992761e+01 7.75199948e+00 1.82050422e+00\n",
      " 4.52659999e+00 8.78751542e+00 8.40541919e+00 6.79420298e+00\n",
      " 1.31443051e+01 1.38109577e+01 4.98816571e+00 3.95092185e+00\n",
      " 1.36771452e+01 1.38211011e+01 7.21211790e+00 4.75836386e+00\n",
      " 1.49843306e+01 1.32903723e+01 5.89519796e+00 1.42550933e+01\n",
      " 6.29158417e+00 1.55342138e+01 1.39905151e+00 4.98586854e+00\n",
      " 1.06019417e+01 7.84405766e+00 1.40085550e+01 1.43155616e+01\n",
      " 1.01817910e+01 5.82852583e+00 2.67519799e+00 8.33055644e+00\n",
      " 1.14677186e+01 4.18959739e+00 4.08615363e+00 5.59847858e+00\n",
      " 4.09173147e+00 1.17233990e+01 6.22385754e+00 2.94655741e+00\n",
      " 3.17604429e+00 1.40839560e+00 9.25013240e+00 8.52332496e+00\n",
      " 1.24978164e+01 4.75104327e+00 1.45688162e+01 1.26345895e+01\n",
      " 1.22965931e+01 8.12176399e+00 1.93897999e+00 9.26692331e+00\n",
      " 3.40248700e+00 6.95549623e+00 1.55303759e+01 6.98725275e-01\n",
      " 1.32285495e+01 5.14679966e+00 1.77417745e+00 1.17234932e+01\n",
      " 1.17556995e+00 7.76744276e+00 6.35662203e+00 6.40143155e+00\n",
      " 5.44884617e-01 1.48199648e+01 5.72020223e+00 4.47690164e-01\n",
      " 1.59847318e+01 1.51312037e+01 6.51864295e+00 1.07278743e+00\n",
      " 1.42299950e+01 1.40290990e+01 5.34405368e+00 3.02694754e+00\n",
      " 1.22493224e+01 1.27386100e+01 1.41425639e+01 1.08474216e+01\n",
      " 1.58502280e+01 1.12642667e+00 1.41274539e+01 4.40726256e+00\n",
      " 1.61677679e+00 1.00178086e-01 1.52229137e+01 5.04620052e+00\n",
      " 2.47696310e+00 1.74929436e+00 3.49768797e+00 5.76208034e+00\n",
      " 1.22491809e+01 1.32944818e+00 3.13464433e+00 9.63179863e+00\n",
      " 7.94396798e+00 1.48722168e+01 2.86716676e+00 3.38672852e+00\n",
      " 1.58451509e+01 1.30626621e+01 1.37489787e+01 1.05720513e+01\n",
      " 7.79341660e-01 1.05774803e+01 3.35384096e+00 1.05677554e+01\n",
      " 2.95919838e+00 1.01048747e+01 7.50301793e+00 6.62039018e-01\n",
      " 2.23792781e-01 1.18368013e+01 1.38233837e+01 8.52419955e+00\n",
      " 1.20666541e+01 1.10237495e+01 4.43154843e+00 5.60378827e+00\n",
      " 1.92691408e+00 7.24356360e-01 1.38807955e+01 8.58048856e-01\n",
      " 1.32682028e+01 6.31728994e+00 1.14900354e+00 1.47704036e-04\n",
      " 1.47704036e-04]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (23899,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/timmy/Desktop/LLM_prompts/original_classifier_contrast.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/timmy/Desktop/LLM_prompts/original_classifier_contrast.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prefix \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./test_payload/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/timmy/Desktop/LLM_prompts/original_classifier_contrast.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_text_1,y_text_1 \u001b[39m=\u001b[39m process_normal_data(prefix \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m3txt_sample10_trans_enc_utf8.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/timmy/Desktop/LLM_prompts/original_classifier_contrast.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_attack_load_1,y_attack_load_1 \u001b[39m=\u001b[39m process_attack_data(prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m7attacked_932_loading.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/timmy/Desktop/LLM_prompts/original_classifier_contrast.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/timmy/Desktop/LLM_prompts/original_classifier_contrast.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(X_set))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/timmy/Desktop/LLM_prompts/original_classifier_contrast.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(X_set[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/timmy/Desktop/LLM_prompts/original_classifier_contrast.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(X_set),np\u001b[39m.\u001b[39marray(y_set)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (23899,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "prefix = \"./test_payload/\"\n",
    "X_text_1,y_text_1 = process_normal_data(prefix + \"3txt_sample10_trans_enc_utf8.csv\")\n",
    "X_attack_load_1,y_attack_load_1 = process_attack_data(prefix + \"7attacked_932_loading.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = \"./pre_content_1/\"\n",
    "\n",
    "# #encrypted text\n",
    "# X_text_1,y_text_1 = process_normal_data(prefix + \"1txt_sample5clean_enc_ip159.csv\")\n",
    "# X_text_2,y_text_2 = process_normal_data(prefix + \"2txt_sample9_trans_enc_utf8.csv\")\n",
    "# X_text_3,y_text_3 = process_normal_data(prefix + \"3txt_sample10_trans_enc_utf8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # process attack data\n",
    "# X_attack_load_1,y_attack_load_1 = process_attack_data(prefix + \"7attacked_932_loading.csv\")\n",
    "# X_attack_load_2,y_attack_load_2 = process_attack_data(prefix + \"8webcam932_novideo_load_ip12.csv\")\n",
    "# X_attack_load_3,y_attack_load_3 = process_attack_data(prefix + \"9webcam5020_novideo_load_ip134.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concoct the train set\n",
    "X_train = np.row_stack((X_text_1,X_attack_load_1))\n",
    "y_train = np.concatenate((y_text_1, y_attack_load_1),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with dropout\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_num, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(100,return_sequences=True))\n",
    "# model.add(LSTM(100,return_sequences=True))\n",
    "# model.add(LSTM(100,return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=64,shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
